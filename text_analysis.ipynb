{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import txt_norm as t\n",
    "import moviedata as m\n",
    "from contractions2 import CONTRACTION_MAP\n",
    "from ast import literal_eval\n",
    "import nltk\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data = pd.read_csv('dataset/movie_metadata_cleaned.csv')\n",
    "movies_data['genres'] = movies_data['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "movies_data['production_companies'] = movies_data['production_companies'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "movies_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overviews=pd.DataFrame(movies_data, columns=['title','id','overview'])\n",
    "a =overviews['overview'][2]\n",
    "overviews['title'][2]\n",
    "overviews.head()\n",
    "#overviews.dtypes\n",
    "#type(overviews['overview'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overviews = overviews.apply(str)\n",
    "len(overviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=overviews['overview'][4]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=t.expand_contractions(a,CONTRACTION_MAP)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=t.remove_special_characters(b)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= t.remove_stopwords(b, stopword_list=list(ENGLISH_STOP_WORDS))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(['averaged_perceptron_tagger',\n",
    "               'universal_tagset',\n",
    "               'wordnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=nltk.word_tokenize(b)\n",
    "c=t.nltk.pos_tag(b, tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.normalize_text(c)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
